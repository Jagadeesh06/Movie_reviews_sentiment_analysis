{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer \n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_reviews(path):\n",
    "    filenames = os.listdir(path)\n",
    "    reviews = []\n",
    "    for filename in filenames:\n",
    "        with open(path+filename) as f:\n",
    "            reviews.append(f.read())\n",
    "    df = pd.DataFrame((reviews),columns=['reviews'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "train_pos_df = extract_reviews('train/pos/')\n",
    "train_neg_df = extract_reviews('train/neg/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For a movie that gets no respect there sure ar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bizarre horror movie filled with famous faces ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A solid, if unremarkable film. Matthau, as Ein...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's a strange feeling to sit alone in a theat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You probably all already know this by now, but...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  sentiment\n",
       "0  For a movie that gets no respect there sure ar...          1\n",
       "1  Bizarre horror movie filled with famous faces ...          1\n",
       "2  A solid, if unremarkable film. Matthau, as Ein...          1\n",
       "3  It's a strange feeling to sit alone in a theat...          1\n",
       "4  You probably all already know this by now, but...          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pos_df['sentiment'] = np.ones(len(train_pos_df), dtype=np.int8)\n",
    "train_pos_df.head()           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Working with one of the best Shakespeare sourc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well...tremors I, the original started off in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ouch! This one was a bit painful to sit throug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've seen some crappy movies in my life, but t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Carriers\" follows the exploits of two guys an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  sentiment\n",
       "0  Working with one of the best Shakespeare sourc...          0\n",
       "1  Well...tremors I, the original started off in ...          0\n",
       "2  Ouch! This one was a bit painful to sit throug...          0\n",
       "3  I've seen some crappy movies in my life, but t...          0\n",
       "4  \"Carriers\" follows the exploits of two guys an...          0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_neg_df['sentiment'] = np.zeros(len(train_neg_df), dtype=np.int8)\n",
    "train_neg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.concat([train_pos_df, train_neg_df],axis=0, ignore_index=True)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Shuffle the rows of the dataframe so that there is a random mix of postive and negative reviews. This step is necessary for performing cross-validation later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great little thriller. I was expecting some ty...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nothing could have saved this movie, not even ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This was a good movie. It wasn't your typical ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From the pen of Richard Condon (The Manchurian...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I suppose that today this film has relevance b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  sentiment\n",
       "0  Great little thriller. I was expecting some ty...          1\n",
       "1  Nothing could have saved this movie, not even ...          0\n",
       "2  This was a good movie. It wasn't your typical ...          1\n",
       "3  From the pen of Richard Condon (The Manchurian...          0\n",
       "4  I suppose that today this film has relevance b...          0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarly load the test dataset\n",
    "\n",
    "test_pos_df = extract_reviews('test/pos/')\n",
    "test_neg_df = extract_reviews('test/neg/')\n",
    "\n",
    "test_pos_df['sentiment'] = np.ones(len(test_pos_df), dtype=np.int8)\n",
    "test_neg_df['sentiment'] = np.zeros(len(test_neg_df), dtype=np.int8)\n",
    "\n",
    "test_df = pd.concat([test_pos_df, test_neg_df],axis=0, ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yul Brynner was a symbol of villein in the tin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This show has been performed live around the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To sum this story up in a few sentences: A tee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is absolutely beyond question the worst m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A box with a button provides a couple with the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews\n",
       "0  Yul Brynner was a symbol of villein in the tin...\n",
       "1  This show has been performed live around the c...\n",
       "2  To sum this story up in a few sentences: A tee...\n",
       "3  This is absolutely beyond question the worst m...\n",
       "4  A box with a button provides a couple with the..."
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = test_df.sentiment\n",
    "test_df = test_df.drop('sentiment',axis=1)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews = train_df.reviews\n",
    "test_reviews = test_df.reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer(r'([a-zA-Z]+)') \n",
    "\n",
    "\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    tag = pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def preprocess_text(review):\n",
    "    '''\n",
    "    This function preprocesses the comments and sets them up for vectorization.\n",
    "    Input: comment string\n",
    "    Returns: A string after converting the words to lowercase, removing punctuations, and lemmatizing each word\n",
    "    '''\n",
    "    words = [word for word in tokenizer.tokenize(review.lower()) if not word in stop_words]  # convert to lowercase and remove stopwords\n",
    "    clean_words = [word for word in words if len(word)>2]\n",
    "    lemmatized_review = ' '.join([lemmatizer.lemmatize(word,pos= get_wordnet_pos(word)) for word in clean_words]) ## lemmatization\n",
    "    return lemmatized_review  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews = train_reviews.apply(lambda review: preprocess_text(review))\n",
    "test_reviews = test_reviews.apply(lambda review: preprocess_text(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    strip_accents= 'unicode', analyzer='word', max_df = 0.5, ngram_range=(1, 2), sublinear_tf=True,                                  \n",
    "     max_features=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = tfidf_vectorizer.fit_transform(train_reviews)\n",
    "test_features = tfidf_vectorizer.transform(test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 30000)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>tf-idf score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10948</th>\n",
       "      <td>he</td>\n",
       "      <td>396.839791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11454</th>\n",
       "      <td>his</td>\n",
       "      <td>395.151154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25656</th>\n",
       "      <td>they</td>\n",
       "      <td>369.771231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25960</th>\n",
       "      <td>this movie</td>\n",
       "      <td>368.299053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22172</th>\n",
       "      <td>so</td>\n",
       "      <td>363.731333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            token  tf-idf score\n",
       "10948          he    396.839791\n",
       "11454         his    395.151154\n",
       "25656        they    369.771231\n",
       "25960  this movie    368.299053\n",
       "22172          so    363.731333"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_scores = np.sum(train_features.A, axis=0,keepdims=False)\n",
    "p=[]\n",
    "for tag, tfidf_score in zip(feature_names, tfidf_scores):\n",
    "    p.append((tag, tfidf_score))\n",
    "    \n",
    "tfidf_scores_df = pd.DataFrame(p,columns=['token', 'tf-idf score']).sort_values(by = 'tf-idf score', ascending=False)\n",
    "tfidf_scores_df.head() ## top 5 tokens in the corpus by tf-idf score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['sentiment']\n",
    "#X_train, X_test, y_train, y_test = train_test_split(train_features, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(clf, parameters, X, y, n_jobs=-1, n_folds=5, score_func=None,verbose=0):\n",
    "    if score_func:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds, n_jobs=n_jobs, scoring=score_func,verbose =verbose)\n",
    "    else:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, cv=5, verbose =verbose)\n",
    "    gs.fit(X, y)\n",
    "    print (\"Best parameter values: {} and best score = {}\".format(gs.best_params_ , gs.best_score_))\n",
    "    best = gs.best_estimator_\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter values: {'alpha': 0.004} and best score = 0.8804\n"
     ]
    }
   ],
   "source": [
    "clf_mulNB = MultinomialNB()\n",
    "parameters = {'alpha': np.arange(0.001, 0.01,0.001)}\n",
    "mulNB_model = grid_search(clf_mulNB, parameters, train_features, y_train, n_folds=5, score_func='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_mulNB_pred = mulNB_model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics(y_test,y_pred):\n",
    "    print(classification_report(y_test, y_pred ))\n",
    "    display(pd.DataFrame(confusion_matrix(y_test, y_pred), \n",
    "                         columns= ['Predicted -ve', 'Predicted +ve'], index = ['Actual -ve', 'Actual +ve']))\n",
    "    print('The AUC (under ROC curve) score is {}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84     12500\n",
      "           1       0.84      0.83      0.84     12500\n",
      "\n",
      "    accuracy                           0.84     25000\n",
      "   macro avg       0.84      0.84      0.84     25000\n",
      "weighted avg       0.84      0.84      0.84     25000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted -ve</th>\n",
       "      <th>Predicted +ve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual -ve</th>\n",
       "      <td>10468</td>\n",
       "      <td>2032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual +ve</th>\n",
       "      <td>2077</td>\n",
       "      <td>10423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted -ve  Predicted +ve\n",
       "Actual -ve          10468           2032\n",
       "Actual +ve           2077          10423"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC (under ROC curve) score is 0.8356399999999999\n"
     ]
    }
   ],
   "source": [
    "show_metrics(y_test, clf_mulNB_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter values: {'C': 5} and best score = 0.90564\n"
     ]
    }
   ],
   "source": [
    "clf_logreg = LogisticRegression(solver='sag',random_state=42)\n",
    "parameters = {'C': np.arange(1,12,1)}\n",
    "logreg_model = grid_search(clf_logreg, parameters, train_features, y_train, n_folds=10, score_func='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87     12500\n",
      "           1       0.87      0.88      0.87     12500\n",
      "\n",
      "    accuracy                           0.87     25000\n",
      "   macro avg       0.87      0.87      0.87     25000\n",
      "weighted avg       0.87      0.87      0.87     25000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted -ve</th>\n",
       "      <th>Predicted +ve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual -ve</th>\n",
       "      <td>10805</td>\n",
       "      <td>1695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual +ve</th>\n",
       "      <td>1519</td>\n",
       "      <td>10981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted -ve  Predicted +ve\n",
       "Actual -ve          10805           1695\n",
       "Actual +ve           1519          10981"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC (under ROC curve) score is 0.8714400000000001\n",
      "0.87144\n"
     ]
    }
   ],
   "source": [
    "logreg_pred = logreg_model.predict(test_features)\n",
    "show_metrics(y_test, logreg_pred)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, logreg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST {'max_depth': 10, 'n_estimators': 1000} 0.84116\n"
     ]
    }
   ],
   "source": [
    "clf_rf = RandomForestClassifier(random_state=42,n_jobs=-1, min_samples_split=5) \n",
    "parameters = {'n_estimators': [700,1000], 'max_depth': [7,10]}\n",
    "rfmodel = grid_search(clf_rf, parameters, train_features, y_train, n_folds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.57      0.71     12500\n",
      "           1       0.69      0.96      0.80     12500\n",
      "\n",
      "    accuracy                           0.77     25000\n",
      "   macro avg       0.81      0.77      0.76     25000\n",
      "weighted avg       0.81      0.77      0.76     25000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted -ve</th>\n",
       "      <th>Predicted +ve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual -ve</th>\n",
       "      <td>7152</td>\n",
       "      <td>5348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual +ve</th>\n",
       "      <td>520</td>\n",
       "      <td>11980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted -ve  Predicted +ve\n",
       "Actual -ve           7152           5348\n",
       "Actual +ve            520          11980"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC (under ROC curve) score is 0.7652800000000001\n"
     ]
    }
   ],
   "source": [
    "clf_rf = RandomForestClassifier(n_estimators=500, max_depth=10, random_state=42,n_jobs=-1, min_samples_split=5) \n",
    "clf_rf.fit(train_features,y_train)\n",
    "rf_pred = clf_rf.predict(test_features)\n",
    "show_metrics(y_test, rf_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using word embeddings (word2vec)\n",
    "\n",
    "The results from the different classifiers are comparable and acceptable. I think it might be possible to crank up the accuracy and other metrics (precision, recall) by tweaking hyperparameters a bit more, or by using other classification algorithms. But now it's time to experiment with Word2vec, a word embedding technique which provided a fresh impetus to the NLP community since the original paper by Mikolov et al. in 2013.\n",
    "\n",
    "The following section is inspired by this [Kaggle tutorial](https://www.kaggle.com/c/word2vec-nlp-tutorial/overview/part-3-more-fun-with-word-vectors) on Word2vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr. Bean came home yesterday.', 'Whoo!', 'are you coming?']"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "s = 'Mr. Bean came home yesterday. Whoo! are you coming?'\n",
    "sent_tokenize(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_words( review, remove_stopwords=False ):\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "    #\n",
    "    regex_tokenizer = RegexpTokenizer(r'([a-zA-Z]+)') \n",
    "    words = regex_tokenizer.tokenize(review.lower())\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    #\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def review_to_sentences(review, remove_stopwords=False ):\n",
    "    '''\n",
    "    Function to split a review into parsed sentences. \n",
    "    Returns a list of sentences, where each sentence is a list of words.\n",
    "    '''\n",
    "    sentences = sent_tokenize(review.strip())  # splits the paragraph in to sentences\n",
    "    sentences_list = []\n",
    "    for sentence in sentences:\n",
    "        # If a sentence is empty, skip it\n",
    "        if len(sentence) > 0:\n",
    "        # Otherwise, call sentence_to_words to get a list of words\n",
    "            sentences_list.append(text_to_words(sentence,remove_stopwords)) # split the sentence into words\n",
    "    return sentences_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []  # Initialize an empty list of sentences\n",
    "for review in train_df[\"reviews\"]:\n",
    "    sentences += review_to_sentences(review)\n",
    "\n",
    "for review in test_df[\"reviews\"]:\n",
    "    sentences += review_to_sentences(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-25 17:56:31,167 : INFO : collecting all words and their counts\n",
      "2019-08-25 17:56:31,178 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-08-25 17:56:31,351 : INFO : PROGRESS: at sentence #10000, processed 225235 words, keeping 17080 word types\n",
      "2019-08-25 17:56:31,508 : INFO : PROGRESS: at sentence #20000, processed 447525 words, keeping 24202 word types\n",
      "2019-08-25 17:56:31,662 : INFO : PROGRESS: at sentence #30000, processed 669440 words, keeping 28984 word types\n",
      "2019-08-25 17:56:31,819 : INFO : PROGRESS: at sentence #40000, processed 893873 words, keeping 32874 word types\n",
      "2019-08-25 17:56:31,960 : INFO : PROGRESS: at sentence #50000, processed 1115940 words, keeping 36470 word types\n",
      "2019-08-25 17:56:32,121 : INFO : PROGRESS: at sentence #60000, processed 1341511 words, keeping 39534 word types\n",
      "2019-08-25 17:56:32,254 : INFO : PROGRESS: at sentence #70000, processed 1569482 words, keeping 42470 word types\n",
      "2019-08-25 17:56:32,392 : INFO : PROGRESS: at sentence #80000, processed 1786848 words, keeping 44779 word types\n",
      "2019-08-25 17:56:32,756 : INFO : PROGRESS: at sentence #90000, processed 2010789 words, keeping 47177 word types\n",
      "2019-08-25 17:56:32,974 : INFO : PROGRESS: at sentence #100000, processed 2236563 words, keeping 49303 word types\n",
      "2019-08-25 17:56:33,124 : INFO : PROGRESS: at sentence #110000, processed 2455040 words, keeping 51184 word types\n",
      "2019-08-25 17:56:33,258 : INFO : PROGRESS: at sentence #120000, processed 2675619 words, keeping 52961 word types\n",
      "2019-08-25 17:56:33,388 : INFO : PROGRESS: at sentence #130000, processed 2891451 words, keeping 54749 word types\n",
      "2019-08-25 17:56:33,537 : INFO : PROGRESS: at sentence #140000, processed 3109342 words, keeping 56331 word types\n",
      "2019-08-25 17:56:33,667 : INFO : PROGRESS: at sentence #150000, processed 3330925 words, keeping 57920 word types\n",
      "2019-08-25 17:56:33,809 : INFO : PROGRESS: at sentence #160000, processed 3556670 words, keeping 59464 word types\n",
      "2019-08-25 17:56:33,954 : INFO : PROGRESS: at sentence #170000, processed 3782982 words, keeping 60885 word types\n",
      "2019-08-25 17:56:34,105 : INFO : PROGRESS: at sentence #180000, processed 4007795 words, keeping 62367 word types\n",
      "2019-08-25 17:56:34,240 : INFO : PROGRESS: at sentence #190000, processed 4233412 words, keeping 63711 word types\n",
      "2019-08-25 17:56:34,370 : INFO : PROGRESS: at sentence #200000, processed 4450712 words, keeping 64962 word types\n",
      "2019-08-25 17:56:34,536 : INFO : PROGRESS: at sentence #210000, processed 4675340 words, keeping 66309 word types\n",
      "2019-08-25 17:56:34,694 : INFO : PROGRESS: at sentence #220000, processed 4893399 words, keeping 67446 word types\n",
      "2019-08-25 17:56:34,838 : INFO : PROGRESS: at sentence #230000, processed 5112613 words, keeping 68686 word types\n",
      "2019-08-25 17:56:34,979 : INFO : PROGRESS: at sentence #240000, processed 5331652 words, keeping 69884 word types\n",
      "2019-08-25 17:56:35,140 : INFO : PROGRESS: at sentence #250000, processed 5556694 words, keeping 71008 word types\n",
      "2019-08-25 17:56:35,290 : INFO : PROGRESS: at sentence #260000, processed 5777659 words, keeping 72159 word types\n",
      "2019-08-25 17:56:35,418 : INFO : PROGRESS: at sentence #270000, processed 6003008 words, keeping 73179 word types\n",
      "2019-08-25 17:56:35,555 : INFO : PROGRESS: at sentence #280000, processed 6226137 words, keeping 74553 word types\n",
      "2019-08-25 17:56:35,703 : INFO : PROGRESS: at sentence #290000, processed 6455640 words, keeping 76077 word types\n",
      "2019-08-25 17:56:35,837 : INFO : PROGRESS: at sentence #300000, processed 6680402 words, keeping 77497 word types\n",
      "2019-08-25 17:56:35,963 : INFO : PROGRESS: at sentence #310000, processed 6904288 words, keeping 78778 word types\n",
      "2019-08-25 17:56:36,105 : INFO : PROGRESS: at sentence #320000, processed 7119806 words, keeping 79974 word types\n",
      "2019-08-25 17:56:36,239 : INFO : PROGRESS: at sentence #330000, processed 7338767 words, keeping 81101 word types\n",
      "2019-08-25 17:56:36,380 : INFO : PROGRESS: at sentence #340000, processed 7551748 words, keeping 82188 word types\n",
      "2019-08-25 17:56:36,499 : INFO : PROGRESS: at sentence #350000, processed 7766212 words, keeping 83212 word types\n",
      "2019-08-25 17:56:36,629 : INFO : PROGRESS: at sentence #360000, processed 7988899 words, keeping 84341 word types\n",
      "2019-08-25 17:56:36,763 : INFO : PROGRESS: at sentence #370000, processed 8209281 words, keeping 85298 word types\n",
      "2019-08-25 17:56:36,883 : INFO : PROGRESS: at sentence #380000, processed 8425829 words, keeping 86244 word types\n",
      "2019-08-25 17:56:36,999 : INFO : PROGRESS: at sentence #390000, processed 8650980 words, keeping 87237 word types\n",
      "2019-08-25 17:56:37,122 : INFO : PROGRESS: at sentence #400000, processed 8872643 words, keeping 88159 word types\n",
      "2019-08-25 17:56:37,246 : INFO : PROGRESS: at sentence #410000, processed 9097207 words, keeping 89002 word types\n",
      "2019-08-25 17:56:37,365 : INFO : PROGRESS: at sentence #420000, processed 9318655 words, keeping 89905 word types\n",
      "2019-08-25 17:56:37,479 : INFO : PROGRESS: at sentence #430000, processed 9543733 words, keeping 90840 word types\n",
      "2019-08-25 17:56:37,596 : INFO : PROGRESS: at sentence #440000, processed 9768717 words, keeping 91713 word types\n",
      "2019-08-25 17:56:37,711 : INFO : PROGRESS: at sentence #450000, processed 9988171 words, keeping 92538 word types\n",
      "2019-08-25 17:56:37,840 : INFO : PROGRESS: at sentence #460000, processed 10214193 words, keeping 93407 word types\n",
      "2019-08-25 17:56:37,964 : INFO : PROGRESS: at sentence #470000, processed 10432913 words, keeping 94233 word types\n",
      "2019-08-25 17:56:38,100 : INFO : PROGRESS: at sentence #480000, processed 10656124 words, keeping 95087 word types\n",
      "2019-08-25 17:56:38,252 : INFO : PROGRESS: at sentence #490000, processed 10877925 words, keeping 95846 word types\n",
      "2019-08-25 17:56:38,372 : INFO : PROGRESS: at sentence #500000, processed 11101560 words, keeping 96719 word types\n",
      "2019-08-25 17:56:38,492 : INFO : PROGRESS: at sentence #510000, processed 11326337 words, keeping 97499 word types\n",
      "2019-08-25 17:56:38,611 : INFO : PROGRESS: at sentence #520000, processed 11550113 words, keeping 98222 word types\n",
      "2019-08-25 17:56:38,723 : INFO : PROGRESS: at sentence #530000, processed 11768103 words, keeping 98967 word types\n",
      "2019-08-25 17:56:38,797 : INFO : collected 99426 word types from a corpus of 11911303 raw words and 536641 sentences\n",
      "2019-08-25 17:56:38,799 : INFO : Loading a fresh vocabulary\n",
      "2019-08-25 17:56:38,880 : INFO : min_count=30 retains 15366 unique words (15% of original 99426, drops 84060)\n",
      "2019-08-25 17:56:38,880 : INFO : min_count=30 leaves 11524389 word corpus (96% of original 11911303, drops 386914)\n",
      "2019-08-25 17:56:38,941 : INFO : deleting the raw counts dictionary of 99426 items\n",
      "2019-08-25 17:56:38,945 : INFO : sample=0.001 downsamples 49 most-common words\n",
      "2019-08-25 17:56:38,946 : INFO : downsampling leaves estimated 8441403 word corpus (73.2% of prior 11524389)\n",
      "2019-08-25 17:56:39,032 : INFO : estimated required memory for 15366 words and 200 dimensions: 32268600 bytes\n",
      "2019-08-25 17:56:39,033 : INFO : resetting layer weights\n",
      "2019-08-25 17:56:39,277 : INFO : training model with 4 workers on 15366 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-08-25 17:56:40,308 : INFO : EPOCH 1 - PROGRESS: at 8.41% examples, 710824 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:56:41,314 : INFO : EPOCH 1 - PROGRESS: at 17.97% examples, 759093 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:56:42,320 : INFO : EPOCH 1 - PROGRESS: at 27.73% examples, 775663 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:56:43,321 : INFO : EPOCH 1 - PROGRESS: at 37.28% examples, 784574 words/s, in_qsize 7, out_qsize 1\n",
      "2019-08-25 17:56:44,328 : INFO : EPOCH 1 - PROGRESS: at 46.86% examples, 787914 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:56:45,344 : INFO : EPOCH 1 - PROGRESS: at 56.48% examples, 791181 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:56:46,346 : INFO : EPOCH 1 - PROGRESS: at 66.30% examples, 793940 words/s, in_qsize 6, out_qsize 0\n",
      "2019-08-25 17:56:47,359 : INFO : EPOCH 1 - PROGRESS: at 75.96% examples, 795005 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:56:48,359 : INFO : EPOCH 1 - PROGRESS: at 85.27% examples, 794646 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-25 17:56:49,363 : INFO : EPOCH 1 - PROGRESS: at 94.89% examples, 796205 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:56:49,880 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-25 17:56:49,893 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-25 17:56:49,901 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-25 17:56:49,915 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-25 17:56:49,916 : INFO : EPOCH - 1 : training on 11911303 raw words (8438083 effective words) took 10.6s, 794945 effective words/s\n",
      "2019-08-25 17:56:50,924 : INFO : EPOCH 2 - PROGRESS: at 9.42% examples, 798631 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:56:51,926 : INFO : EPOCH 2 - PROGRESS: at 18.90% examples, 801824 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:56:52,933 : INFO : EPOCH 2 - PROGRESS: at 28.46% examples, 798991 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:56:53,936 : INFO : EPOCH 2 - PROGRESS: at 37.97% examples, 800454 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:56:54,947 : INFO : EPOCH 2 - PROGRESS: at 47.62% examples, 801345 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:56:55,949 : INFO : EPOCH 2 - PROGRESS: at 57.05% examples, 802052 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:56:56,952 : INFO : EPOCH 2 - PROGRESS: at 66.73% examples, 801150 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-25 17:56:57,971 : INFO : EPOCH 2 - PROGRESS: at 76.20% examples, 798855 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:56:58,972 : INFO : EPOCH 2 - PROGRESS: at 85.36% examples, 796508 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:56:59,976 : INFO : EPOCH 2 - PROGRESS: at 94.80% examples, 796447 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:57:00,512 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-25 17:57:00,514 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-25 17:57:00,523 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-25 17:57:00,526 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-25 17:57:00,529 : INFO : EPOCH - 2 : training on 11911303 raw words (8440829 effective words) took 10.6s, 795898 effective words/s\n",
      "2019-08-25 17:57:01,549 : INFO : EPOCH 3 - PROGRESS: at 9.16% examples, 776802 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:57:02,560 : INFO : EPOCH 3 - PROGRESS: at 18.46% examples, 780199 words/s, in_qsize 6, out_qsize 0\n",
      "2019-08-25 17:57:03,569 : INFO : EPOCH 3 - PROGRESS: at 28.06% examples, 784268 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-25 17:57:04,574 : INFO : EPOCH 3 - PROGRESS: at 37.46% examples, 786980 words/s, in_qsize 6, out_qsize 1\n",
      "2019-08-25 17:57:05,574 : INFO : EPOCH 3 - PROGRESS: at 46.78% examples, 786866 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:57:06,589 : INFO : EPOCH 3 - PROGRESS: at 56.13% examples, 787103 words/s, in_qsize 6, out_qsize 1\n",
      "2019-08-25 17:57:07,591 : INFO : EPOCH 3 - PROGRESS: at 62.26% examples, 747490 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:57:08,597 : INFO : EPOCH 3 - PROGRESS: at 69.95% examples, 733080 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-25 17:57:09,606 : INFO : EPOCH 3 - PROGRESS: at 78.62% examples, 732630 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:57:10,617 : INFO : EPOCH 3 - PROGRESS: at 87.89% examples, 737020 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:57:11,619 : INFO : EPOCH 3 - PROGRESS: at 97.23% examples, 741905 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:57:11,890 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-25 17:57:11,900 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-25 17:57:11,902 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-25 17:57:11,914 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-25 17:57:11,915 : INFO : EPOCH - 3 : training on 11911303 raw words (8443712 effective words) took 11.4s, 742721 effective words/s\n",
      "2019-08-25 17:57:12,935 : INFO : EPOCH 4 - PROGRESS: at 9.16% examples, 774644 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:57:13,950 : INFO : EPOCH 4 - PROGRESS: at 18.22% examples, 767319 words/s, in_qsize 6, out_qsize 1\n",
      "2019-08-25 17:57:14,959 : INFO : EPOCH 4 - PROGRESS: at 27.81% examples, 775574 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:57:15,961 : INFO : EPOCH 4 - PROGRESS: at 36.76% examples, 772038 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:57:16,993 : INFO : EPOCH 4 - PROGRESS: at 45.03% examples, 751601 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:57:18,006 : INFO : EPOCH 4 - PROGRESS: at 51.87% examples, 721941 words/s, in_qsize 6, out_qsize 1\n",
      "2019-08-25 17:57:19,012 : INFO : EPOCH 4 - PROGRESS: at 58.66% examples, 701188 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:57:20,017 : INFO : EPOCH 4 - PROGRESS: at 66.90% examples, 698009 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:57:21,021 : INFO : EPOCH 4 - PROGRESS: at 76.28% examples, 708045 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:57:22,022 : INFO : EPOCH 4 - PROGRESS: at 85.36% examples, 714197 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:57:23,028 : INFO : EPOCH 4 - PROGRESS: at 94.39% examples, 718282 words/s, in_qsize 7, out_qsize 1\n",
      "2019-08-25 17:57:23,606 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-25 17:57:23,615 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-25 17:57:23,621 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-25 17:57:23,623 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-25 17:57:23,624 : INFO : EPOCH - 4 : training on 11911303 raw words (8441346 effective words) took 11.7s, 721868 effective words/s\n",
      "2019-08-25 17:57:24,643 : INFO : EPOCH 5 - PROGRESS: at 8.90% examples, 753307 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:57:25,643 : INFO : EPOCH 5 - PROGRESS: at 18.05% examples, 765344 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:57:26,644 : INFO : EPOCH 5 - PROGRESS: at 27.39% examples, 769473 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:57:27,646 : INFO : EPOCH 5 - PROGRESS: at 36.44% examples, 769372 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:57:28,661 : INFO : EPOCH 5 - PROGRESS: at 45.78% examples, 770393 words/s, in_qsize 6, out_qsize 1\n",
      "2019-08-25 17:57:29,669 : INFO : EPOCH 5 - PROGRESS: at 54.89% examples, 770653 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:57:30,676 : INFO : EPOCH 5 - PROGRESS: at 64.36% examples, 771980 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:57:31,679 : INFO : EPOCH 5 - PROGRESS: at 73.70% examples, 773282 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-25 17:57:32,685 : INFO : EPOCH 5 - PROGRESS: at 83.11% examples, 775573 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:57:33,687 : INFO : EPOCH 5 - PROGRESS: at 92.48% examples, 777121 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-25 17:57:34,457 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-25 17:57:34,463 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-25 17:57:34,467 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-25 17:57:34,481 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-25 17:57:34,482 : INFO : EPOCH - 5 : training on 11911303 raw words (8441678 effective words) took 10.8s, 778481 effective words/s\n",
      "2019-08-25 17:57:34,482 : INFO : training on a 59556515 raw words (42205648 effective words) took 55.2s, 764566 effective words/s\n",
      "2019-08-25 17:57:34,487 : INFO : precomputing L2-norms of word weight vectors\n",
      "2019-08-25 17:57:34,642 : INFO : saving Word2Vec object under 300features_40minwords_10context, separately None\n",
      "2019-08-25 17:57:34,648 : INFO : not storing attribute vectors_norm\n",
      "2019-08-25 17:57:34,651 : INFO : not storing attribute cum_table\n",
      "/Users/debashis/anaconda3/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 1.0581315636634827 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-25 17:57:35,000 : INFO : saved 300features_40minwords_10context\n"
     ]
    }
   ],
   "source": [
    "# Import the built-in logging module and configure it so that Word2Vec \n",
    "import logging\n",
    "import time\n",
    "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',level=logging.INFO)\n",
    "    \n",
    "# Set parameter values for word2vec model\n",
    "num_features = 200    # Word vector dimensionality                      \n",
    "min_word_count = 30   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.models import word2vec\n",
    "start = time.time()\n",
    "model = word2vec.Word2Vec(sentences, workers=num_workers, \n",
    "            size=num_features, min_count = min_word_count, \n",
    "            window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)\n",
    "end = time.time()\n",
    "print('Took {} mins.'.format((end - start)/60))\n",
    "# It can be helpful to create a meaningful model name and \n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model_name = \"300features_40minwords_10context\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44209871284575264"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cosine similarity between any two words in the vocabulary\n",
    "model.wv.similarity('movie', 'thriller')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('drama', 0.7082782983779907),\n",
       " ('giallo', 0.6919577717781067),\n",
       " ('melodrama', 0.6373547911643982),\n",
       " ('farce', 0.6364995241165161),\n",
       " ('flick', 0.6363845467567444),\n",
       " ('yarn', 0.6272774934768677),\n",
       " ('suspense', 0.6271798610687256),\n",
       " ('mystery', 0.5976229906082153),\n",
       " ('thrillers', 0.5886460542678833),\n",
       " ('chiller', 0.5811585187911987)]"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 similar words\n",
    "model.wv.most_similar('thriller')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999994"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The vectors are normalized\n",
    "np.sum(model.wv['thriller']**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15366"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No. of words in the vocabulary\n",
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15366, 200)"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each row is the word vector for that word\n",
    "model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we would represent each piece of review with a vector as follows:**\n",
    "1. Loop over each word in the review, if the word is in the vocabulary, get its word vector.\n",
    "2. Sum all the word vectors found in this way and divide by the number of vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_feature_vector(model,words):\n",
    "    '''Returns the average of all the word vectors corresponding to a particular review'''\n",
    "    vector_sum = np.zeros(num_features,)\n",
    "    c=0\n",
    "    for word in words:\n",
    "        if word in model.wv.vocab:\n",
    "            vector_sum  = vector_sum + model.wv[word]\n",
    "            c = c+1\n",
    "    vector_sum /= c\n",
    "    return vector_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 200)\n",
      "(25000, 200)\n"
     ]
    }
   ],
   "source": [
    "train_wordvec_features = np.empty((train_df.shape[0], num_features))\n",
    "test_wordvec_features = np.empty((test_df.shape[0], num_features))\n",
    "\n",
    "for row in range(train_df.shape[0]):  \n",
    "    train_wordvec_features[row,:] = text_to_feature_vector(model, text_to_words(train_df['reviews'][row],remove_stopwords=True))\n",
    "\n",
    "for row in range(test_df.shape[0]):\n",
    "    test_wordvec_features[row,:] = text_to_feature_vector(model, text_to_words(test_df['reviews'][row], remove_stopwords=True))\n",
    "\n",
    "print(train_wordvec_features.shape)\n",
    "print(test_wordvec_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter values: {'C': 38} and best score = 0.86688\n"
     ]
    }
   ],
   "source": [
    "clf_logreg_word2vec = LogisticRegression(solver='sag',random_state=42)\n",
    "parameters = {'C': np.arange(20,40,2)}\n",
    "logreg_model_word2vec = grid_search(clf_logreg, parameters, train_wordvec_features, y_train, n_folds=10, score_func='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.87     12500\n",
      "           1       0.87      0.86      0.87     12500\n",
      "\n",
      "    accuracy                           0.87     25000\n",
      "   macro avg       0.87      0.87      0.87     25000\n",
      "weighted avg       0.87      0.87      0.87     25000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted -ve</th>\n",
       "      <th>Predicted +ve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual -ve</th>\n",
       "      <td>10898</td>\n",
       "      <td>1602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual +ve</th>\n",
       "      <td>1723</td>\n",
       "      <td>10777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted -ve  Predicted +ve\n",
       "Actual -ve          10898           1602\n",
       "Actual +ve           1723          10777"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC (under ROC curve) score is 0.867\n",
      "0.867\n"
     ]
    }
   ],
   "source": [
    "logreg_pred_word2vec_tr = logreg_model_word2vec.predict(test_wordvec_features)\n",
    "logreg_pred_word2vec_tr = LogisticRegression(C=100,solver='sag',random_state=42).fit(train_wordvec_features,y_train).predict(test_wordvec_features)\n",
    "show_metrics(y_test,logreg_pred_word2vec_tr)\n",
    "print(accuracy_score(y_test,logreg_pred_word2vec_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Misclassification example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0\n",
      "Actual: 1\n"
     ]
    }
   ],
   "source": [
    "print('Predicted: %i'%logreg_pred_word2vec_tr[2])\n",
    "print('Actual: %i'%y_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To sum this story up in a few sentences: A teenage girl (Amy) uses her hot body and \"supposed\" virginity to entice a young troubled guy (Matt) with a potential football scholarship to provide her a \"Full Ride\" out of town. Come to find out she has quite the reputation & has slept with many football players in the past hoping they would offer her the same deal. Both of these kids have come from troubled & dysfunctional homes. Matt's mothers a alcoholic who repeatedly embarrasses him in front of his friends & Amy's mother had a bad reputation herself & got pregnant with Amy at a a young age. Matt falls in love with Amy & tries to straighten out his life for her. Very predictable ending. The actress that plays \"Amy\" is actually 33 years old trying to play a teenager!\n"
     ]
    }
   ],
   "source": [
    "print(test_df.iloc[2]['reviews'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*To be honest, I don't see how the above review is actually classified as positive. I'd think it rather has negative connotations.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83     12500\n",
      "           1       0.83      0.83      0.83     12500\n",
      "\n",
      "    accuracy                           0.83     25000\n",
      "   macro avg       0.83      0.83      0.83     25000\n",
      "weighted avg       0.83      0.83      0.83     25000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted -ve</th>\n",
       "      <th>Predicted +ve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual -ve</th>\n",
       "      <td>10407</td>\n",
       "      <td>2093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual +ve</th>\n",
       "      <td>2142</td>\n",
       "      <td>10358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted -ve  Predicted +ve\n",
       "Actual -ve          10407           2093\n",
       "Actual +ve           2142          10358"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC (under ROC curve) score is 0.8306\n"
     ]
    }
   ],
   "source": [
    "clf_rf_word2vec = RandomForestClassifier(n_estimators=600, max_depth=15, random_state=42,n_jobs=-1, min_samples_split=3) \n",
    "clf_rf_word2vec.fit(train_wordvec_features,y_train)\n",
    "rf_pred_word2vec = clf_rf_word2vec.predict(test_wordvec_features)\n",
    "\n",
    "show_metrics(y_test,rf_pred_word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural nets: Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "0.14.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
